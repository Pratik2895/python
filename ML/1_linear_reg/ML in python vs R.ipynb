{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [1.]\n",
      "Intercept: 1.0\n",
      "Predicted value: [7.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create some sample data\n",
    "x = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a linear regression model and fit the data\n",
    "model = LinearRegression().fit(x, y)\n",
    "\n",
    "# Print the model coefficients\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "\n",
    "# Predict a new value\n",
    "new_x = np.array([[6]])\n",
    "new_y = model.predict(new_x)\n",
    "print('Predicted value:', new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'library(\"tidyverse\")\\nlibrary(\"broom\")\\n\\n# Create some sample data\\nx <- c(1, 2, 3, 4, 5)\\ny <- c(2, 3, 4, 5, 6)\\n\\n# Create a linear regression model and fit the data\\nmodel <- lm(y ~ x)\\n\\n# Print the model coefficients\\ntidy(model)\\n\\n# Predict a new value\\nnew_x <- data.frame(x = 6)\\nnew_y <- predict(model, new_x)\\nprint(new_y)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''library(\"tidyverse\")\n",
    "library(\"broom\")\n",
    "\n",
    "# Create some sample data\n",
    "x <- c(1, 2, 3, 4, 5)\n",
    "y <- c(2, 3, 4, 5, 6)\n",
    "\n",
    "# Create a linear regression model and fit the data\n",
    "model <- lm(y ~ x)\n",
    "\n",
    "# Print the model coefficients\n",
    "tidy(model)\n",
    "\n",
    "# Predict a new value\n",
    "new_x <- data.frame(x = 6)\n",
    "new_y <- predict(model, new_x)\n",
    "print(new_y)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[0.73330424 0.73326515]]\n",
      "Intercept: [-2.05778139]\n",
      "Predicted value: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create some sample data\n",
    "X = [[0.5, 1], [1, 1.5], [1.5, 2], [2, 2.5], [2.5, 3]]\n",
    "y = [0, 0, 1, 1, 1]\n",
    "\n",
    "# Create a logistic regression model and fit the data\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "# Print the model coefficients\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "\n",
    "# Predict a new value\n",
    "new_X = [[1, 2]]\n",
    "new_y = model.predict(new_X)\n",
    "print('Predicted value:', new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Create some sample data\\nx <- c(0.5, 1, 1.5, 2, 2.5)\\ny <- c(0, 0, 1, 1, 1)\\n\\n# Create a logistic regression model and fit the data\\nmodel <- glm(y ~ x, family = binomial(link = \"logit\"))\\n\\n# Print the model coefficients\\nsummary(model)\\n\\n# Predict a new value\\nnew_x <- data.frame(x = 1.2)\\nnew_y <- predict(model, new_x, type = \"response\")\\nprint(new_y)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Create some sample data\n",
    "x <- c(0.5, 1, 1.5, 2, 2.5)\n",
    "y <- c(0, 0, 1, 1, 1)\n",
    "\n",
    "# Create a logistic regression model and fit the data\n",
    "model <- glm(y ~ x, family = binomial(link = \"logit\"))\n",
    "\n",
    "# Print the model coefficients\n",
    "summary(model)\n",
    "\n",
    "# Predict a new value\n",
    "new_x <- data.frame(x = 1.2)\n",
    "new_y <- predict(model, new_x, type = \"response\")\n",
    "print(new_y)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create some sample data\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [0, 1, 1, 0]\n",
    "\n",
    "# Create a decision tree model and fit the data\n",
    "model = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "# Predict a new value\n",
    "new_X = [[0, 1]]\n",
    "new_y = model.predict(new_X)\n",
    "print('Predicted value:', new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the rpart package\\nlibrary(rpart)\\n\\n# Create some sample data\\ndata(iris)\\nx <- iris[, 1:4]\\ny <- iris[, 5]\\n\\n# Create a decision tree model and fit the data\\nmodel <- rpart(y ~ ., data = data.frame(x, y))\\n\\n# Print the model summary\\nsummary(model)\\n\\n# Plot the decision tree\\nplot(model)\\ntext(model)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load the rpart package\n",
    "library(rpart)\n",
    "\n",
    "# Create some sample data\n",
    "data(iris)\n",
    "x <- iris[, 1:4]\n",
    "y <- iris[, 5]\n",
    "\n",
    "# Create a decision tree model and fit the data\n",
    "model <- rpart(y ~ ., data = data.frame(x, y))\n",
    "\n",
    "# Print the model summary\n",
    "summary(model)\n",
    "\n",
    "# Plot the decision tree\n",
    "plot(model)\n",
    "text(model)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a SVM model and fit the training data\n",
    "model = SVC(kernel='linear', C=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data(iris)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Create a SVM model and fit the training data\n",
    "library(e1071)\n",
    "model <- svm(Species ~ ., data = trainData, kernel = \"linear\", cost = 10)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "predicted <- predict(model, testData[,-5])\n",
    "actual <- testData[,5]\n",
    "accuracy <- sum(predicted == actual)/length(actual)\n",
    "print(paste(\"Accuracy:\", accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomforestclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create some sample data\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Random Forest model and fit the training data\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the randomForest package\n",
    "library(randomForest)\n",
    "\n",
    "# Create some sample data\n",
    "data(iris)\n",
    "x <- iris[, 1:4]\n",
    "y <- iris[, 5]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Create a Random Forest model and fit the training data\n",
    "model <- randomForest(Species ~ ., data = trainData, ntree = 100, mtry = 2)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "predicted <- predict(model, testData)\n",
    "actual <- testData[,5]\n",
    "accuracy <- sum(predicted == actual)/length(actual)\n",
    "print(paste(\"Accuracy:\", accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kfoldcross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 1.0\n",
      "Train score: 1.0\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Create some sample data\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([3, 7, 11, 15])\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Train score:', model.score(X_train, y_train))\n",
    "    print('Test score:', model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library(caret)\n",
    "\n",
    "# Load some sample data\n",
    "data(iris)\n",
    "x <- iris[, 1:4]\n",
    "y <- iris[, 5]\n",
    "\n",
    "# Create a linear regression model\n",
    "model <- train(x, y, method = \"lm\")\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "set.seed(42)\n",
    "cv <- trainControl(method = \"cv\", number = 5)\n",
    "cv_results <- train(x, y, method = \"lm\", trControl = cv)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(cv_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "data = pd.DataFrame({\n",
    "    'Name': ['Rob', 'Michael', 'Mohan', 'Ismail', 'Kory'],\n",
    "    'Age': [27, 29, 29, 28, 42],\n",
    "    'Income($)': [70000, 90000, 61000, 60000, 150000]\n",
    "})\n",
    "\n",
    "# Extract the features from the dataframe\n",
    "X = data[['Age', 'Income($)']]\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a k-means clustering model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit the model to the scaled features\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Predict the cluster labels for each data point\n",
    "labels = kmeans.predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters using matplotlib\n",
    "plt.scatter(X_scaled[labels==0, 0], X_scaled[labels==0, 1], s=100, c='red', label='Cluster 1')\n",
    "plt.scatter(X_scaled[labels==1, 0], X_scaled[labels==1, 1], s=100, c='blue', label='Cluster 2')\n",
    "plt.scatter(X_scaled[labels==2, 0], X_scaled[labels==2, 1], s=100, c='green', label='Cluster 3')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='yellow', label='Centroids')\n",
    "plt.title('Clusters of Customers')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income($)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset into a dataframe\n",
    "data <- data.frame(\n",
    "    Name = c('Rob', 'Michael', 'Mohan', 'Ismail', 'Kory'),\n",
    "    Age = c(27, 29, 29, 28, 42),\n",
    "    Income = c(70000, 90000, 61000, 60000, 150000)\n",
    ")\n",
    "\n",
    "# Extract the features from the dataframe\n",
    "X <- data[, c('Age', 'Income')]\n",
    "\n",
    "# Scale the features using scale()\n",
    "X_scaled <- scale(X)\n",
    "\n",
    "# Create a k-means clustering model with 3 clusters\n",
    "kmeans_model <- kmeans(X_scaled, centers = 3)\n",
    "\n",
    "# Print the cluster centers\n",
    "print(kmeans_model$centers)\n",
    "\n",
    "# Print the cluster assignments for each data point\n",
    "print(kmeans_model$cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes model and fit the training data\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the naivebayes package\n",
    "library(naivebayes)\n",
    "\n",
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Create a Naive Bayes model and fit the training data\n",
    "model <- naive_bayes(Species ~ ., data = trainData)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "predicted <- predict(model, testData)\n",
    "actual <- testData[,5]\n",
    "accuracy <- sum(predicted == actual)/length(actual)\n",
    "print(paste(\"Accuracy:\", accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Accuracy: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Create a SVM model\n",
    "model = SVC()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(iris.data, iris.target)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Accuracy:', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library(caret)\n",
    "\n",
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid <- expand.grid(\n",
    "    .C = c(0.1, 1, 10),\n",
    "    .gamma = c(0.1, 1, 10),\n",
    "    .kernel = c(\"linear\", \"radial\")\n",
    ")\n",
    "\n",
    "# Create a SVM model\n",
    "model <- train(\n",
    "    x = iris[, 1:4],\n",
    "    y = iris[, 5],\n",
    "    method = \"svmRadial\",\n",
    "    tuneGrid = param_grid,\n",
    "    trControl = trainControl(method = \"cv\", number = 5)\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(model$bestTune)\n",
    "print(model$results$Accuracy[which.max(model$results$Accuracy)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: [18.9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create some sample data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [3, 7, 11, 15]\n",
    "\n",
    "# Create a linear regression model with L1 regularization\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict a new value\n",
    "new_X = [[9, 10]]\n",
    "new_y = model.predict(new_X)\n",
    "print('Predicted value:', new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: [18.97506234]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create some sample data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [3, 7, 11, 15]\n",
    "\n",
    "# Create a linear regression model with L2 regularization\n",
    "model = Ridge(alpha=0.1)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict a new value\n",
    "new_X = [[9, 10]]\n",
    "new_y = model.predict(new_X)\n",
    "print('Predicted value:', new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'library(glmnet)\\n\\n# Create some sample data\\nx <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), ncol = 2)\\ny <- c(3, 7, 11, 15)\\n\\n# Perform Lasso regularization\\nlasso_model <- glmnet(x, y, alpha = 1)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''library(glmnet)\n",
    "\n",
    "# Create some sample data\n",
    "x <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), ncol = 2)\n",
    "y <- c(3, 7, 11, 15)\n",
    "\n",
    "# Perform Lasso regularization\n",
    "lasso_model <- glmnet(x, y, alpha = 1)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'library(glmnet)\\n\\n# Create some sample data\\nx <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), ncol = 2)\\ny <- c(3, 7, 11, 15)\\n\\n# Perform Ridge regularization\\nridge_model <- glmnet(x, y, alpha = 0)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''library(glmnet)\n",
    "\n",
    "# Create some sample data\n",
    "x <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), ncol = 2)\n",
    "y <- c(3, 7, 11, 15)\n",
    "\n",
    "# Perform Ridge regularization\n",
    "ridge_model <- glmnet(x, y, alpha = 0)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "library(class)\n",
    "knn_model <- knn(train = trainData[,1:4], test = testData[,1:4], cl = trainData[,5], k = 3)\n",
    "\n",
    "# Print the predicted classes for the testing data\n",
    "print(knn_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a PCA model with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the model to the data\n",
    "X_pca = pca.fit_transform(iris.data)\n",
    "\n",
    "# Visualize the data in the new 2D space\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=iris.target)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Create a PCA model with 2 components\n",
    "pca_model <- prcomp(iris[, 1:4], scale = TRUE)\n",
    "\n",
    "# Extract the principal components\n",
    "PC1 <- pca_model$x[, 1]\n",
    "PC2 <- pca_model$x[, 2]\n",
    "\n",
    "# Visualize the data in the new 2D space\n",
    "plot(PC1, PC2, col = iris$Species, pch = 19, xlab = \"PC1\", ylab = \"PC2\")\n",
    "legend(\"topright\", legend = levels(iris$Species), col = 1:3, pch = 19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bagging and boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the caret package\n",
    "library(caret)\n",
    "\n",
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Define the training control\n",
    "train_control <- trainControl(method = \"cv\", number = 5)\n",
    "\n",
    "# Perform bagging with a decision tree model\n",
    "bag_model <- train(\n",
    "    x = iris[, 1:4],\n",
    "    y = iris[, 5],\n",
    "    method = \"treebag\",\n",
    "    trControl = train_control\n",
    ")\n",
    "\n",
    "# Perform boosting with a decision tree model\n",
    "boost_model <- train(\n",
    "    x = iris[, 1:4],\n",
    "    y = iris[, 5],\n",
    "    method = \"adaboost\",\n",
    "    trControl = train_control\n",
    ")\n",
    "\n",
    "# Print the accuracy of each model\n",
    "print(paste(\"Bagging Accuracy:\", bag_model$results$Accuracy))\n",
    "print(paste(\"Boosting Accuracy:\", boost_model$results$Accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the xgboost package\n",
    "library(xgboost)\n",
    "\n",
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Convert the data to a DMatrix format\n",
    "trainDMatrix <- xgb.DMatrix(data = trainData[, 1:4], label = trainData[, 5])\n",
    "testDMatrix <- xgb.DMatrix(data = testData[, 1:4], label = testData[, 5])\n",
    "\n",
    "# Define the parameters for the XGBoost model\n",
    "params <- list(\n",
    "    objective = \"multi:softmax\",\n",
    "    num_class = 3,\n",
    "    max_depth = 3,\n",
    "    eta = 0.3,\n",
    "    nthread = 2\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model <- xgb.train(\n",
    "    params = params,\n",
    "    data = trainDMatrix,\n",
    "    nrounds = 10\n",
    ")\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "predicted <- predict(xgb_model, testDMatrix)\n",
    "actual <- testData[,5]\n",
    "accuracy <- sum(predicted == actual)/length(actual)\n",
    "print(paste(\"Accuracy:\", accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the xgboost package\\nlibrary(xgboost)\\n\\n# Load the iris dataset\\ndata(iris)\\n\\n# Split the dataset into training and testing sets\\ntrainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\\ntrainData <- iris[trainIndex,]\\ntestData <- iris[-trainIndex,]\\n\\n# Convert the data to a DMatrix format\\ntrainDMatrix <- xgb.DMatrix(data = trainData[, 1:4], label = trainData[, 5])\\ntestDMatrix <- xgb.DMatrix(data = testData[, 1:4], label = testData[, 5])\\n\\n# Define the parameters for the XGBoost model\\nparams <- list(\\n    objective = \"multi:softmax\",\\n    num_class = 3,\\n    max_depth = 3,\\n    eta = 0.3,\\n    nthread = 2\\n)\\n\\n# Train the XGBoost model\\nxgb_model <- xgb.train(\\n    params = params,\\n    data = trainDMatrix,\\n    nrounds = 10\\n)\\n\\n# Predict the testing data and calculate the accuracy\\npredicted <- predict(xgb_model, testDMatrix)\\nactual <- testData[,5]\\naccuracy <- sum(predicted == actual)/length(actual)\\nprint(paste(\"Accuracy:\", accuracy))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load the xgboost package\n",
    "library(xgboost)\n",
    "\n",
    "# Load the iris dataset\n",
    "data(iris)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "trainIndex <- sample(1:nrow(iris), round(0.7*nrow(iris)), replace=FALSE)\n",
    "trainData <- iris[trainIndex,]\n",
    "testData <- iris[-trainIndex,]\n",
    "\n",
    "# Convert the data to a DMatrix format\n",
    "trainDMatrix <- xgb.DMatrix(data = trainData[, 1:4], label = trainData[, 5])\n",
    "testDMatrix <- xgb.DMatrix(data = testData[, 1:4], label = testData[, 5])\n",
    "\n",
    "# Define the parameters for the XGBoost model\n",
    "params <- list(\n",
    "    objective = \"multi:softmax\",\n",
    "    num_class = 3,\n",
    "    max_depth = 3,\n",
    "    eta = 0.3,\n",
    "    nthread = 2\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model <- xgb.train(\n",
    "    params = params,\n",
    "    data = trainDMatrix,\n",
    "    nrounds = 10\n",
    ")\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "predicted <- predict(xgb_model, testDMatrix)\n",
    "actual <- testData[,5]\n",
    "accuracy <- sum(predicted == actual)/length(actual)\n",
    "print(paste(\"Accuracy:\", accuracy))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "AdaBoost Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Random Forest model with 100 trees\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Random Forest Accuracy:', accuracy)\n",
    "\n",
    "# Create an AdaBoost model with 100 decision stumps\n",
    "ada_model = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data and calculate the accuracy\n",
    "y_pred = ada_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('AdaBoost Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
